{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2efbe95-153f-4431-b077-2aca1e61deba",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from Tokenizers import TokenizersConfig, Tokenizers\n",
    "\n",
    "# load the pre-trained checkpoints\n",
    "checkpoint = torch.load('data/Tokenizer_iter3_plus_AS2M.pt')\n",
    "\n",
    "cfg = TokenizersConfig(checkpoint['cfg'])\n",
    "BEATs_tokenizer = Tokenizers(cfg)\n",
    "BEATs_tokenizer.load_state_dict(checkpoint['model'])\n",
    "BEATs_tokenizer.eval()\n",
    "\n",
    "# tokenize the audio and generate the labels\n",
    "audio_input_16khz = torch.randn(1, 10000)\n",
    "padding_mask = torch.zeros(1, 10000).bool()\n",
    "\n",
    "labels = BEATs_tokenizer.extract_labels(audio_input_16khz, padding_mask=padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ea485fc-ac4a-4135-9668-e05a0e17b747",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([767, 500,  36,  36,  36, 967,  36, 199, 425, 290,  36,  36, 425, 350,\n",
       "        350, 364, 670, 400, 244, 788,  36, 603, 350, 425])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7592f879-586b-41d5-ac43-5fca51893e62",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 predicted labels of the 0th audio are ['/m/09x0r', '/m/096m7z', '/m/07rgkc5', '/m/0chx_', '/m/0cj0r'] with probability of tensor([0.2042, 0.1681, 0.1365, 0.1313, 0.0756], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 1th audio are ['/m/07rgkc5', '/m/096m7z', '/m/0chx_', '/m/09x0r', '/m/0cj0r'] with probability of tensor([0.2471, 0.2129, 0.1894, 0.1852, 0.0468], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 2th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/0cj0r'] with probability of tensor([0.1996, 0.1466, 0.1317, 0.1056, 0.0537], grad_fn=<UnbindBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from BEATs import BEATs, BEATsConfig\n",
    "\n",
    "# load the fine-tuned checkpoints\n",
    "checkpoint = torch.load('data/BEATs_iter3_plus_AS2M_finetuned_on_AS2M_cpt2.pt')\n",
    "\n",
    "cfg = BEATsConfig(checkpoint['cfg'])\n",
    "BEATs_model = BEATs(cfg)\n",
    "BEATs_model.load_state_dict(checkpoint['model'])\n",
    "BEATs_model.eval()\n",
    "\n",
    "# predict the classification probability of each class\n",
    "audio_input_16khz = torch.randn(3, 10000)\n",
    "padding_mask = torch.zeros(3, 10000).bool()\n",
    "\n",
    "probs = BEATs_model.extract_features(audio_input_16khz, padding_mask=padding_mask)[0]\n",
    "\n",
    "for i, (top5_label_prob, top5_label_idx) in enumerate(zip(*probs.topk(k=5))):\n",
    "    top5_label = [checkpoint['label_dict'][label_idx.item()] for label_idx in top5_label_idx]\n",
    "    print(f'Top 5 predicted labels of the {i}th audio are {top5_label} with probability of {top5_label_prob}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvpr24",
   "language": "python",
   "name": "cvpr24"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}